# CCL2019“小牛杯”中文幽默计算评测
CCL2019，“小牛杯”中文幽默计算任务的数据集及baseline  

任务说明参见CCL2019官方网站：http://www.cips-cl.org/static/CCL2019/call-evaluation.html 。  
任务每个阶段的排名将在该GitHub公布。  

两个任务取测试集的部分数据构建开发集。  
在比赛的前四个阶段，将根据模型在开发集上的得分对参赛队伍排名。  
完整测试集将在10月5日0点放出，队伍的最终排名由模型在完整测试集上的得分决定。

文件说明：
```、
-- data
    -- task1    # 子任务一：生成幽默识别数据
        -- task1_train.csv    # 训练集
        -- task1_development.csv    # 开发集
    -- task2    # 子任务二：中文幽默等级划分数据
        -- task2_train.csv    # 训练集
        -- task2_development.csv    # 开发集
-- baseline
    -- task1_baseline.ipynb    # 使用LSTM
    -- task2_baseline.ipynb    # 使用LSTM
```  

第一阶段队伍排名：  

 | 队伍名称 | task1_f1  | task2_macro_f1 | score | rank |
 |:----:|:----:|:----:|:----:|:----:|
 | SXU-NLP | 0.8406 | 0.4969 | 0.7031 | 1 |
 | 金山AI Lab-MRC | 0.8531 | 0.3600 | 0.6559 | 2 |
 | 清博AI | 0.8439 | 0.3671 | 0.6532 | 3 |
 | Tenacious Birds | 0.8463 | 0.3417 | 0.6444 | 4 |  
 
第二阶段队伍排名：  

 | 队伍名称 | task1_f1  | task2_macro_f1 | score | rank |
 |:----:|:----:|:----:|:----:|:----:| 
 | Huawei MT Squad | 0.8936 | 0.4599 | 0.7202 | 1 |
 | 清博AI | 0.8665 | 0.4675 | 0.7069 | 2 |
 | 学习强国 | 0.8630 |  0.4686 | 0.7052 | 3 |
 | SXU-NLP | 0.8603|  0.4602 | 0.7002 | 4 |
 | 金山AI Lab-MRC | 0.8522 | 0.4518 | 0.6920 | 5 |
 | 贝岗不断电 | 0.8382 |  0.4448 | 0.6808 | 6 |
 | 不叫塞尔达 | 0.8536 |  0.3576 | 0.6552 | 7 |
 | Tenacious Birds | 0.8463 | 0.3417 | 0.6444 | 8 |

第三阶段队伍排名：

 | 队伍名称 | task1_f1  | task2_macro_f1 | score | rank |
 |:----:|:----:|:----:|:----:|:----:| 
 | Huawei MT Squad | 0.9024 | 0.4953 | 0.7395 | 1 |
 | SXU-NLP | 0.8613 | 0.4748 | 0.7067 | 2 |
 | 清博AI | 0.8699 | 0.4530 | 0.7032 | 3 |
 | 三群五队 | 0.8593 | 0.4618 | 0.7003 | 4 |
 | np菜鸟 | 0.8524 | 0.4575 | 0.6944 | 5 |
 | Tenacious Birds | 0.8463 | 0.4423 | 0.6847 | 6 |
 | 饮水思源队 | 0.8303 | 0.4597 | 0.6821 | 7 |
 | 金山AI Lab-MRC | 0.8404 | 0.4244 | 0.6740 | 8 |
 | jxnu-小黑 | 0.8422 | 0.4116 | 0.6699 | 9 |
 | 罗小黑战队 | 0.8098 | 0.3971 | 0.6447 | 10 |
 | 111 | 0.8418 | 0.3259 | 0.6355 | 11 |
 | 贝岗不断电 | 0.6482 | 0.3128 | 0.5141 | 12 |
 
 最终排名由队伍在完整测试集上的得分决定。
